---
title: "Week 8: Accuracy Measures and Cross-validation Strategies for Data with Temporal and/ or Spatial Structures"
format:
  revealjs:
    slide-number: true
    show-slide-number: all 
---

# Loss function

- Function that calculates loss for a single data point

$e_i = y - \hat{y}$

$e_i^2 = (y - \hat{y})^2$

# Cost function

- Calculates loss for the entire data sets 

$$ME = \frac{1}{n}\sum_{i=1}^n e_i$$

# Numeric outcome: Evaluations

## Prediction accuracy measures (cost functions)

Mean Error

$$ME = \frac{1}{n}\sum_{i=1}^n e_i$$


- Error can be both negative and positive. So they can cancel each other during the summation.

## Mean Absolute Error (L1 loss)

$$MAE = \frac{1}{n}\sum_{i=1}^n |e_i|$$

##  Mean Squared Error (L2 loss)

$$MSE = \frac{1}{n}\sum_{i=1}^n e^2_i$$


## Mean Percentage Error

$$MPE = \frac{1}{n}\sum_{i=1}^n \frac{e_i}{y_i}$$


## Mean Absolute Percentage Error

$$MAPE = \frac{1}{n}\sum_{i=1}^n |\frac{e_i}{y_i}|$$




## Root Mean Squared Error

$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^n e^2_i}$$


## Visualizaion of error distribution

Graphical representations reveal more than metrics alone.

## Accuracy Measures on Training Set vs Test Set

Accuracy measure on training set: Tells about the model fit


Accuracy measure on test set: Model ability to predict new data



## Evaluate Classifier Against Benchmarks

Naive approach: approach relies soley on $Y$

Outcome: Numeric

Naive  Benchmark:  Average ($\bar{Y}$)

## Time series cross-validation


![](crossvalidation.png)

Image credit: Professor Rob Hyndman

## LOOCV

![](loocv.png)

Blue - Training set

Orange - Test set

Not good for time series data. Why?


## Evaluation on a rolling forecasting origin

- There are a series of test sets, each consisting of a single observation.

- The corresponding training set consists only of observations that occurred prior to the observation that forms the test set.

##


![](cv1.svg)

Training set - blue, Test set - red

The forecast accuracy is computed by averaging over the test sets. 

Source: Hyndman, R. J., & Athanasopoulos, G. (2018). Forecasting: principles and practice. OTexts.

## Multi-step ahead forecast


![](cv1.svg)

Training set - blue, Test set - red



Source: Hyndman, R. J., & Athanasopoulos, G. (2018). Forecasting: principles and practice. OTexts.

## Cross-validation in Space

![](space_cv.png)

Source: Roberts, D. R., Bahn, V., Ciuti, S., Boyce, M. S., Elith, J., Guillera‐Arroita, G., ... & Dormann, C. F. (2017). Cross‐validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure. Ecography, 40(8), 913-929

## Case 1

![](space_cv.png)

## Case 2

![](scv.png)

Source: Ploton, P., Mortier, F., Réjou-Méchain, M., Barbier, N., Picard, N., Rossi, V., ... & Pélissier, R. (2020). Spatial validation reveals poor predictive performance of large-scale ecological mapping models. Nature communications, 11(1), 1-11.

##

![](scv.png)
