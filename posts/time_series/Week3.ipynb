{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Week 3-4: AR/ MA/ ARMA/ ARIMA'\n",
        "format:\n",
        "  revealjs:\n",
        "    slide-number: true\n",
        "    show-slide-number: all\n",
        "---"
      ],
      "id": "7f9ff8b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recap: Stationarity\n"
      ],
      "id": "e462e56d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-column: margin\n",
        "#| echo: true\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean = 0\n",
        "std = 1 \n",
        "num_samples = 100\n",
        "samples = numpy.random.normal(mean, std, size=num_samples)\n",
        "plt.plot(samples)\n",
        "plt.show()"
      ],
      "id": "4f4c79ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ACF \n"
      ],
      "id": "03686157"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "plot_acf(samples, lags=20)\n",
        "plt.show()"
      ],
      "id": "a0968d3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "White noise implies stationarity. Stationarity does not imply white noise.\n",
        "\n",
        "## Non-Stationary Time Series\n",
        "\n",
        "**1. Deterministic trend**\n",
        "\n",
        "$$Y_t  = f(t) + \\epsilon_t$$\n",
        "\n",
        "\n",
        "where $\\epsilon_t \\sim iid(0, \\sigma^2)$, $t = 1, 2, ...T$\n",
        "\n",
        "Mean of the process is time dependent, but the variance of the process is constant.\n",
        "\n",
        "A trend is deterministic if it is a nonrandom function of time.\n",
        "\n",
        "## Non-Stationary Time Series (cont.)\n",
        "\n",
        "**2. Random walk** \n",
        "\n",
        "$$Y_t = Y_{t-1} + \\epsilon_t$$\n",
        "\n",
        "- Random walk has a stochastic trend.\n",
        "\n",
        "- Model behind naive method.\n",
        "\n",
        "A trend is said to be stochastic if it is a random function of time.\n",
        "\n",
        "\n",
        "\n",
        "## Non-Stationary Time Series (cont.)\n",
        "\n",
        "**3. Random walk with drift**\n",
        "\n",
        "$$Y_t = \\alpha+  Y_{t-1} + \\epsilon_t$$\n",
        "\n",
        "- Random walk with drift has a stochastic trend and a deterministic trend.\n",
        "\n",
        "- Model behind drift method.\n",
        "\n",
        "\n",
        "## Random walk\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "  Y_t &= Y_{t-1} + \\epsilon_t \\\\\n",
        "     Y_1    &= Y_0 + \\epsilon_1 \\\\\n",
        "         Y_2 &=  Y_1 + \\epsilon_2=Y_0 + \\epsilon_1 + \\epsilon_2\\\\\n",
        "          Y_3 &=  Y_2 + \\epsilon_3=Y_0 + \\epsilon_1 + \\epsilon_2 +\\epsilon_3\\\\\n",
        "          .   \\\\\n",
        "          Y_t &=Y_{t-1} + \\epsilon_t=Y_0 + \\epsilon_1 + \\epsilon_2 + \\epsilon_3 +...+ \\epsilon_t = Y_0 + \\sum_{i=1}^{t} \\epsilon_t\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Mean: $E(Y_t) = Y_0$.\n",
        "\n",
        "Variance: $Var(Y_t)=t \\sigma^2$.\n",
        "\n",
        "## Random walk with drift\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "  Y_t &= Y_{t-1} + \\epsilon_t \\\\\n",
        "     Y_1    &= \\alpha+Y_0 + \\epsilon_1 \\\\\n",
        "         Y_2 &= \\alpha+ Y_1 + \\epsilon_2=2 \\alpha+Y_0 + \\epsilon_1 + \\epsilon_2\\\\\n",
        "          Y_3 &= \\alpha+ Y_2 + \\epsilon_3= 3 \\alpha+ Y_0 + \\epsilon_1 + \\epsilon_2 +\\epsilon_3\\\\\n",
        "          .   \\\\\n",
        "          Y_t &= \\alpha+Y_{t-1} + \\epsilon_t= t \\alpha+ Y_0 + \\epsilon_1 + \\epsilon_2 + \\epsilon_3 +...+ \\epsilon_t \\\\\n",
        "          Y_t &= t \\alpha + Y_0 + \\sum_{i=1}^{t} \\epsilon_t\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Random walk with drift (cont.)\n",
        "\n",
        "\n",
        "It has a *deterministic trend* $(Y_0 + t \\alpha)$ and a *stochastic trend* $\\sum_{i=1}^{t} \\epsilon_t$.\n",
        "\n",
        "Mean: $E(Y_t) = Y_0 + t\\alpha$\n",
        "\n",
        "Variance: $Var(Y_t) = t\\sigma^2$.\n",
        "\n",
        "There is a trend in both mean and variance. \n",
        "\n",
        "\n",
        "## Common trend removal (de-trending) procedures\n",
        "\n",
        "1. Deterministic trend: Time-trend regression\n",
        "\n",
        "      The trend can be removed by fitting a deterministic polynomial time trend. The residual series after removing the trend will give us the de-trended series.\n",
        "\n",
        "1. Stochastic trend: Differencing\n",
        " \n",
        "      The process is also known as a **Difference-stationary process**.\n",
        "      \n",
        "# Notation: I(d)\n",
        "\n",
        "Integrated to order $d$: Series can be made stationary by differencing $d$ times.\n",
        " \n",
        " - Known as $I(d)$ process.\n",
        " \n",
        "\n",
        "**Question: ** Show that random walk process is an $I(1)$ process.\n",
        "\n",
        "The random walk process is called a unit root process.\n",
        "(If one of the roots turns out to be one, then the process is called unit root process.)\n",
        "\n",
        "## Random walk\n"
      ],
      "id": "c661002f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import numpy as np\n",
        "rw = np.cumsum(samples)\n",
        "plt.plot(rw)\n",
        "plt.show()"
      ],
      "id": "8cbabde0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random walk - ACF\n"
      ],
      "id": "2f577597"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_acf(rw, lags=20)\n",
        "plt.show()"
      ],
      "id": "c1404f95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Difference series\n"
      ],
      "id": "a79ff9f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.DataFrame(rw, columns = ['Values'])\n",
        "df['Lag 1'] = df['Values'].diff()\n",
        "df['Lag 2'] = df['Values'].diff().diff()\n",
        "df"
      ],
      "id": "981ded2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Lag 1 series\n"
      ],
      "id": "c860f31d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(df['Values'].diff())\n",
        "plt.show()"
      ],
      "id": "2435a653",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ACF Lag 1 series\n"
      ],
      "id": "a99ab754"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "diff = df['Lag 1']\n",
        "plot_acf(diff.dropna(), lags=20)\n",
        "plt.show()"
      ],
      "id": "0611c755",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2\n"
      ],
      "id": "3ee21895"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: false\n",
        "import numpy as np, pandas as pd\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
        "\n",
        "# Import data\n",
        "df = pd.read_csv('wwwusage.csv', names=['value'], header=0)\n",
        "\n",
        "# Original Series\n",
        "fig, axes = plt.subplots(2, 2, sharex=True)\n",
        "axes[0, 0].plot(df.value); axes[0, 0].set_title('Original Series')\n",
        "plot_acf(df.value, ax=axes[0, 1], lags=np.arange(len(df)))\n",
        "\n",
        "# 1st Differencing\n",
        "axes[1, 0].plot(df.value.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
        "plot_acf(df.value.diff().dropna(), ax=axes[1, 1], lags=np.arange(len(df) - 1))\n",
        "plt.show()"
      ],
      "id": "17412c83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##\n"
      ],
      "id": "75a258ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
        "\n",
        "# Import data\n",
        "df = pd.read_csv('wwwusage.csv', names=['value'], header=0)\n",
        "\n",
        "# Original Series\n",
        "fig, axes = plt.subplots(2, 2, sharex=True)\n",
        "axes[0, 0].plot(df.value); axes[0, 0].set_title('Original Series')\n",
        "plot_acf(df.value, ax=axes[0, 1], lags=np.arange(len(df)))\n",
        "\n",
        "# 1st Differencing\n",
        "axes[1, 0].plot(df.value.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
        "plot_acf(df.value.diff().dropna(), ax=axes[1, 1], lags=np.arange(len(df) - 1))\n",
        "plt.show()"
      ],
      "id": "b2628bf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2nd order differencing\n"
      ],
      "id": "e7fb76a8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_acf(df.value.diff().diff().dropna())\n",
        "plt.show()"
      ],
      "id": "e4cc1def",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variance stabilization\n",
        "\n",
        "Eg:\n",
        "\n",
        "- Square root: $W_t = \\sqrt{Y_t}$\n",
        "\n",
        "- Logarithm: $W_t = log({Y_t})$\n",
        "\n",
        "     - This very useful.\n",
        "     \n",
        "     - Interpretable: Changes in a log value are **relative (percent) changes on the original sclae**.\n",
        "     \n",
        "## Monthly Airline Passenger Numbers 1949-1960\n"
      ],
      "id": "db1b8e2e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "airpassenger = pd.read_csv('AirPassengers.csv')\n",
        "from datetime import datetime\n",
        "import plotnine\n",
        "from plotnine import *\n",
        "airpassenger['Month']= pd.to_datetime(airpassenger['Month'])\n",
        "ggplot(airpassenger, aes(x='Month', y='#Passengers'))+geom_line()"
      ],
      "id": "ed87ee83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monthly Airline Passenger Numbers 1949-1960 - log\n"
      ],
      "id": "d788478e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import numpy as np\n",
        "airpassenger['naturallog'] = np.log(airpassenger['#Passengers']) \n",
        "ggplot(airpassenger, aes(x='Month', y='naturallog'))+geom_line()"
      ],
      "id": "a88c2977",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Box-Cox transformation\n",
        "\n",
        "$$\n",
        "  w_t=\\begin{cases}\n",
        "    log(y_t), & \\text{if $\\lambda=0$} \\newline\n",
        "    (Y_t^\\lambda - 1)/ \\lambda, & \\text{otherwise}.\n",
        "  \\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "Different values of $\\lambda$ gives you different transformations.\n",
        "\n",
        "- $\\lambda=1$: No **substantive** transformation\n",
        "\n",
        "- $\\lambda = \\frac{1}{2}$: Square root plus linear transformation\n",
        "\n",
        "- $\\lambda=0$: Natural logarithm\n",
        "\n",
        "- $\\lambda = -1$: Inverse plus 1\n",
        "\n",
        "Balance the seasonal fluctuations and random variation across the series.\n",
        "\n",
        "## Box-Cox transformation\n"
      ],
      "id": "758361c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# import modules\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        " \n",
        "y2,fitted_lambda = stats.boxcox(airpassenger['#Passengers'])"
      ],
      "id": "b1361a06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Box-Cox transformation: Exploring the output\n"
      ],
      "id": "1dd04315"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "fitted_lambda"
      ],
      "id": "881439de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y2"
      ],
      "id": "c8541ceb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ARMA(p, q) model\n",
        "\n",
        "\n",
        "$$Y_t=c+\\phi_1Y_{t-1}+...+\\phi_p Y_{t-p}+ \\theta_1\\epsilon_{t-1}+...+\\theta_q\\epsilon_{t-q}+\\epsilon_t$$\n",
        "\n",
        "- These are stationary models.\n",
        "\n",
        "- They are only suitable for **stationary series**.\n",
        "\n",
        "## ARIMA(p, d, q) model\n",
        "\n",
        "Differencing --> ARMA\n",
        "\n",
        "**Step 1: Differencing**\n",
        "\n",
        "$$Y'_t = (1-B)^dY_t$$\n",
        "\n",
        "**Step 2: ARMA**\n",
        "\n",
        "$$Y'_t=c+\\phi_1Y'_{t-1}+...+\\phi_p Y'_{t-p}+ \\theta_1\\epsilon_{t-1}+...+\\theta_q\\epsilon_{t-q}+\\epsilon_t$$\n",
        "\n",
        "# Step 1: Plot data\n",
        "\n",
        "1. Detect unusual observations in the data\n",
        "\n",
        "1. Detect non-stationarity by visual inspections of plots\n",
        "\n",
        "Stationary series:\n",
        "\n",
        "- has a constant mean value and fluctuates around the mean.\n",
        "\n",
        "- constant variance.\n",
        "\n",
        "- no pattern predictable in the long-term.\n",
        "\n",
        "##\n"
      ],
      "id": "3b97044e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime import *\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.utils.plotting import plot_series\n",
        "y = load_airline()\n",
        "plot_series(y)"
      ],
      "id": "c229c8fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Split time series into training and test\n",
        "\n",
        "Specify the forecast horizon\n"
      ],
      "id": "fa96074a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "fh = ForecastingHorizon(\n",
        "    pd.PeriodIndex(pd.date_range(\"1960-01\", periods=12, freq=\"M\")), is_relative=False\n",
        ")\n",
        "fh"
      ],
      "id": "fc9f666c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot training and test series\n"
      ],
      "id": "4be15ce1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "y_train, y_test = temporal_train_test_split(y, fh=fh)\n",
        "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])"
      ],
      "id": "cc0b696a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##\n",
        "\n",
        "1. Need transformations?\n",
        "\n",
        "2. Need differencing?\n",
        "\n",
        "## Step 3: Apply transformations\n"
      ],
      "id": "5ce1afee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import numpy as np\n",
        "y_train.naturallog = np.log(y_train) \n",
        "plot_series(y_train.naturallog)"
      ],
      "id": "44f5a4c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Take difference series\n",
        "\n",
        "**Identifying non-stationarity by looking at plots**\n",
        "  \n",
        "- Time series plot\n",
        "\n",
        "- The ACF of stationary data drops to zero relatively quickly.\n",
        "\n",
        "- The ACF of non-stationary data decreases slowly.\n",
        "\n",
        "- For non-stationary data, the value of $r_1$ is often large and positive.\n",
        "\n",
        "## Non-seasonal differencing and seasonal differencing\n",
        "\n",
        "**Non seasonal first-order differencing:** $Y'_t=Y_t - Y_{t-1}$\n",
        "\n",
        "<!--Miss one observation-->\n",
        "\n",
        "**Non seasonal second-order differencing:** $Y''_t=Y'_t - Y'_{t-1}$\n",
        "\n",
        "<!--Miss two observations-->\n",
        "\n",
        "**Seasonal differencing:** $Y_t - Y_{t-m}$\n",
        "\n",
        "<!--To get rid from prominent seasonal components. -->\n",
        "\n",
        "- For monthly, $m=12$, for quarterly, $m=4$.\n",
        "\n",
        "<!--We will loosefirst 12 observations-->\n",
        "\n",
        "\n",
        "- Seasonally differenced series will have $T-m$ observations.\n",
        "<!--Usually we do not consider differencing more than twice. -->\n",
        "\n",
        "> There are times differencing once is not enough. However, in practice,it is almost never necessary to go beyond second-order differencing.\n",
        "<!--Even the second-order differencing is very rare.-->\n",
        "\n",
        "## ACF of log-transformation series\n"
      ],
      "id": "a1a49835"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_acf(y_train.naturallog, lags=50)"
      ],
      "id": "cc4da783",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Take seasonal difference series\n"
      ],
      "id": "83ef4186"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y_train.naturallog.diff12 = y_train.naturallog.diff(12)\n",
        "y_train.naturallog.diff12"
      ],
      "id": "b7343bab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Take seasonal difference series (cont.)\n"
      ],
      "id": "b18e7389"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y_train.naturallog.diff12.head(20)"
      ],
      "id": "c62f4f34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ACF - diff(log(data), 12)\n"
      ],
      "id": "98c1b059"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_acf(y_train.naturallog.diff12.dropna(), lags=50)\n",
        "plt.show()"
      ],
      "id": "687918d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ACF - First differencing on diff(log(data), 12)\n"
      ],
      "id": "130ec78a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y_train.naturallog.diff12.diff = y_train.naturallog.diff12.diff()\n",
        "plot_acf(y_train.naturallog.diff12.diff.dropna(), lags=50)\n",
        "plt.show()"
      ],
      "id": "b4e51288",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PACF - First differencing on diff(log(data), 12)\n"
      ],
      "id": "cc72f7ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_pacf(y_train.naturallog.diff12.diff.dropna(), lags=50)\n",
        "plt.show()"
      ],
      "id": "539cfc42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing for nonstationarity for the presence of unit roots\n",
        "\n",
        "- Dickey and Fuller (DF) test\n",
        "\n",
        "- Augmented DF test\n",
        "\n",
        "- Phillips and Perron (PP) nonparametric test\n",
        "\n",
        "- Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test\n",
        "\n",
        "## KPSS test\n",
        "H0: Series is level or trend stationary.\n",
        "\n",
        "H1: Series is not stationary.\n",
        "\n",
        "## KPSS test\n"
      ],
      "id": "ae70586a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "def kpss_test(series, **kw):    \n",
        "    statistic, p_value, n_lags, critical_values = kpss(series, **kw)\n",
        "    # Format Output\n",
        "    print(f'KPSS Statistic: {statistic}')\n",
        "    print(f'p-value: {p_value}')\n",
        "    print(f'num lags: {n_lags}')\n",
        "    print('Critial Values:')\n",
        "    for key, value in critical_values.items():\n",
        "        print(f'   {key} : {value}')\n",
        "    print(f'Result: The series is {\"not \" if p_value < 0.05 else \"\"}stationary')\n",
        "\n",
        "kpss_test(y_train.naturallog)"
      ],
      "id": "a104891e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KPSS test\n"
      ],
      "id": "17ecf203"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "kpss_test(y_train.naturallog.diff12.dropna())"
      ],
      "id": "914e6f42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "kpss_test(y_train.naturallog.diff12.diff.dropna())"
      ],
      "id": "319a3bc7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KPSS test\n",
        "\n",
        "- KPSS test may not necessarily reject the null hypothesis (that the series is level or trend stationary) even if a series is steadily increasing or decreasing.\n",
        "\n",
        "- The word ‘deterministic’ implies the slope of the trend in the series does not change permanently. That is, even if the series goes through a shock, it tends to regain its original path.\n",
        "\n",
        "source: https://www.machinelearningplus.com/time-series/kpss-test-for-stationarity/\n",
        "\n",
        "## KPSS test\n",
        "\n",
        "\n",
        "- By default, it tests for stationarity around a ‘mean’ only.\n",
        "\n",
        "- To turn ON the stationarity testing around a trend, you need to explicitly pass the regression='ct' parameter to the kpss\n"
      ],
      "id": "a9bfba14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "kpss_test(y_train.naturallog.diff12.dropna(), regression='ct')"
      ],
      "id": "4baf1873",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "kpss_test(y_train.naturallog.diff12.diff.dropna())"
      ],
      "id": "1073e6b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ADF test\n"
      ],
      "id": "9ba87501"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def adf_test(series):\n",
        "    result = adfuller(series, autolag='AIC')\n",
        "    print(f'ADF Statistic: {result[0]}')\n",
        "    print(f'p-value: {result[1]}')\n",
        "    for key, value in result[4].items():\n",
        "        print('Critial Values:')\n",
        "        print(f'   {key}, {value}')\n",
        "\n",
        "series = df.loc[:, 'value'].values\n"
      ],
      "id": "73b83785",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "H0: Series is not stationary\n",
        "\n",
        "H1: Series is stationary\n",
        "\n",
        "## ADF test\n"
      ],
      "id": "209cddf1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "adf_test(y_train.naturallog)"
      ],
      "id": "fe682a4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "adf_test(y_train.naturallog.diff12.dropna())"
      ],
      "id": "d90c5958",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "adf_test(y_train.naturallog.diff12.diff.dropna())"
      ],
      "id": "77084bd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KPSS vs ADF test\n",
        "\n",
        "If a series is stationary according to the KPSS test by setting regression='ct' and is not stationary according to the ADF test, it means the series is stationary around a deterministic trend.\n",
        "\n",
        "Further reading: \n",
        "\n",
        "Kwiatkowski, D.; Phillips, P. C. B.; Schmidt, P.; Shin, Y. (1992). Testing the null hypothesis of stationarity against the alternative of a unit root. Journal of Econometrics, 54 (1-3): 159-178.\n",
        "\n",
        "# Step 5: Examine the ACF/PACF to identify a suitable model\n",
        "\n",
        "## AR(p)\n",
        "\n",
        "- ACF dies out in an exponential or damped\n",
        "sine-wave manner.\n",
        "\n",
        "- there is a significant spike at lag $p$ in PACF, but\n",
        "none beyond $p$.\n",
        "\n",
        "## MA(q)\n",
        "\n",
        "- ACF has all zero spikes beyond the $q^{th}$ spike.\n",
        "\n",
        "- PACF dies out in an exponential or damped\n",
        "sine-wave manner.\n",
        "\n",
        "## Seasonal components\n",
        "\n",
        "- The seasonal part of an AR or MA model will be seen\n",
        "in the seasonal lags of the PACF and ACF.\n",
        "\n",
        "\n",
        "## ARIMA(0,0,0)(0,0,1)12 will show\n",
        " \n",
        "  - a spike at lag 12 in the ACF but no other significant spikes.\n",
        "\n",
        "  - The PACF will show exponential decay in the seasonal lags  12, 24, 36, . . . .\n",
        "  \n",
        "## ARIMA(0,0,0)(1,0,0)12 will show\n",
        "\n",
        "  - exponential decay in the seasonal lags of the ACF.\n",
        "    \n",
        "  - a single significant spike at lag 12 in the PACF.\n",
        "\n",
        "\n",
        "## Step 5: Examine the ACF/PACF to identify a suitable model (cont.)\n",
        "\n",
        "- $d=1$ and $D=1$ (from step 4)\n",
        "\n",
        "- Significant spike at lag 1 in ACF suggests\n",
        "non-seasonal MA(1) component.\n",
        "\n",
        "- Significant spike at lag 12 in ACF suggests seasonal\n",
        "MA(1) component.\n",
        "\n",
        "- Initial candidate model: $ARIMA(0,1,1)(0,1,1)_{12}$.\n",
        "\n",
        "- By analogous logic applied to the PACF, we could also have started with $ARIMA(1,1,0)(1,1,0)_{12}$.\n",
        "  \n",
        "## Models   \n",
        "  \n",
        "**Initial model:**\n",
        "\n",
        "$ARIMA(0,1,1)(0,1,1)_{12}$\n",
        "\n",
        "$ARIMA(1,1,0)(1,1,0)_{12}$\n",
        "\n",
        "**Try some variations of the initial model:**\n",
        "\n",
        "$ARIMA(0,1,1)(1,1,1)_{12}$\n",
        "\n",
        "$ARIMA(1,1,1)(1,1,0)_{12}$\n",
        "\n",
        "$ARIMA(1,1,1)(1,1,1)_{12}$\n",
        "\n",
        "##\n",
        "\n",
        "**Try some variations**\n",
        "\n",
        "Both the ACF and PACF show significant spikes at lag 3, and almost significant spikes at lag 3, indicating that some additional non-seasonal terms need to be included in the model.\n",
        "\n",
        "$ARIMA(3,1,1)(1,1,1)_{12}$\n",
        "\n",
        "$ARIMA(1,1,3)(1,1,1)_{12}$\n",
        "\n",
        "$ARIMA(3,1,3)(1,1,1)_{12}$\n",
        "\n",
        "## Fitting ARIMA models\n"
      ],
      "id": "ba6fb654"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from sktime.forecasting.arima import ARIMA\n",
        "forecaster1 = ARIMA(  \n",
        "    order=(1, 1, 0),\n",
        "    seasonal_order=(1, 1, 0, 12),\n",
        "    suppress_warnings=True)\n",
        "forecaster1.fit(y_train.naturallog)    "
      ],
      "id": "8bca6da9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Check residual series\n"
      ],
      "id": "93cf744d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "fhtrain = ForecastingHorizon(\n",
        "    pd.PeriodIndex(pd.period_range(start='1949-01', end='1959-12', freq='M')), is_relative=False\n",
        ")\n",
        "fhtrain"
      ],
      "id": "82c824f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain predictions for the training period\n"
      ],
      "id": "0bc4d535"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y_pred_train = forecaster1.predict(fhtrain)\n",
        "y_pred_train"
      ],
      "id": "14264c07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain residual series\n"
      ],
      "id": "b302758a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "residual = y_train.naturallog - y_pred_train\n",
        "residual"
      ],
      "id": "a90ce6ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot residuals\n"
      ],
      "id": "e2526f29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_series(residual)"
      ],
      "id": "6ee16d8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot residuals (cont.)\n"
      ],
      "id": "f95a44ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_acf(residual.dropna(), lags=50)"
      ],
      "id": "ce3c1101",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot residuals (cont.)\n"
      ],
      "id": "7687f048"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.hist(residual)\n",
        "plt.show()"
      ],
      "id": "700f5f7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Your turn: remove the outlier and draw the histogram\n",
        "\n",
        "## Ljung-Box Test\n",
        "\n",
        "H0: Residuals are not serially correlated.\n",
        "\n",
        "H1: Residuals are serially correlated.\n"
      ],
      "id": "e524745d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "sm.stats.acorr_ljungbox(residual.dropna(), lags=[20], return_df=True)"
      ],
      "id": "e46777ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate forecasts\n"
      ],
      "id": "dcd03910"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y_pred_1 = forecaster1.predict(fh)\n",
        "y_pred_1"
      ],
      "id": "fb00ac92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Back transformation\n"
      ],
      "id": "5ca24b12"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "y_pred_1.exp = np.exp(y_pred_1)\n",
        "y_pred_1.exp"
      ],
      "id": "61614a94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot training, test, and forecasts\n"
      ],
      "id": "42028a22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "plot_series(y_train, y_test, y_pred_1.exp, labels=[\"y_train\", \"y_test\", \"y_forecast\"])"
      ],
      "id": "fc33bc07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n"
      ],
      "id": "641f17f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from sktime.performance_metrics.forecasting import \\\n",
        "    mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(y_test, y_pred_1.exp, symmetric=False)"
      ],
      "id": "0319d4cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Turn\n",
        "\n",
        "Fit other variants of ARIMA models and identify the best ARIMA model for the series.\n",
        "\n",
        "## Modelling steps\n",
        "\n",
        "1. Plot the data.\n",
        "\n",
        "2. If necessary, transform the data (using a Box-Cox transformation) to stabilise the variance.\n",
        "\n",
        "3. If the data are non-stationary, take first differences of the data until the data are stationary.\n",
        "\n",
        "4. Examine the ACF/PACF to identify a suitable model.\n",
        "\n",
        "5. Try your chosen model(s), and use the AICc to search for a better model.\n",
        "\n",
        "## Modelling steps (cont.)\n",
        "\n",
        "6. Check the residuals from your chosen model by plotting the ACF of the residuals, and doing a portmanteau test of the residuals. If they do not look like white noise, try a modified model.\n",
        "\n",
        "7. Once the residuals look like white noise, calculate forecasts.\n",
        "\n",
        "\n",
        "\n",
        "Source: Forecasting: Principles and Practice, Rob J Hyndman and George Athanasopoulos\n"
      ],
      "id": "149c05fa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}